{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nB2nroT1bWso"
      },
      "source": [
        "# Sentiment Analyzer - Model Training\n",
        "\n",
        "This notebook trains a logistic regression model for binary sentiment classification (positive/negative).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BSU9cGUkbhrF"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hhWGRYIobrBX"
      },
      "outputs": [],
      "source": [
        "# Load Training Data\n",
        "# Note: For Google Colab, uncomment the following lines:\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "training_path = input('Please enter path to training_data.csv: ')\n",
        "\"\"\"\n",
        "\n",
        "# Default: Assume files are stored locally in the same directory\n",
        "training_path = \"training_data.csv\"\n",
        "\n",
        "print(f\"Loading training data from: {training_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5X1Ugm90cZRA"
      },
      "source": [
        "## Data Loading and Cleaning\n",
        "\n",
        "The only data cleaning done is the removal of punctuation. We have tried other methods of cleaning the data (see `submission_extras.ipynb`), but they have all resulted in lower accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "B0S7MhZg9zcj"
      },
      "outputs": [],
      "source": [
        "# Load and prepare the dataset\n",
        "df = pd.read_csv(training_path)\n",
        "\n",
        "# Select only the Text and Sentiment columns\n",
        "if 'Text' in df.columns and 'Sentiment' in df.columns:\n",
        "    df = df[['Text', 'Sentiment']]\n",
        "else:\n",
        "    # Handle case where columns might have different names\n",
        "    print(\"Available columns:\", df.columns.tolist())\n",
        "    raise ValueError(\"Dataset must contain 'Text' and 'Sentiment' columns\")\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Sentiment distribution:\\n{df['Sentiment'].value_counts()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "c5VR2_WEcfQZ"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function: Remove punctuation and numbers\n",
        "def remove_punct(text):\n",
        "    \"\"\"\n",
        "    Remove punctuation and numbers from text.\n",
        "    \n",
        "    Args:\n",
        "        text (str): Input text string\n",
        "        \n",
        "    Returns:\n",
        "        str: Text with punctuation and numbers removed\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = \"\".join([char for char in str(text) if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "60JeyGAcc1DZ"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to text column\n",
        "print(\"Preprocessing text data...\")\n",
        "df['Text'] = df['Text'].map(lambda text: remove_punct(text))\n",
        "\n",
        "# Display sample of cleaned data\n",
        "print(\"\\nSample of cleaned data:\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qn5Xq9KP_nau"
      },
      "source": [
        "## Feature Extraction with TF-IDF Vectorization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "a1TMWrgJhW--"
      },
      "outputs": [],
      "source": [
        "# Prepare features and labels\n",
        "X = np.array(df['Text'])\n",
        "y = np.array(df['Sentiment'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n",
        "\n",
        "# Initialize and fit TF-IDF vectorizer\n",
        "# Parameters optimized for best performance:\n",
        "# - strip_accents='unicode': Remove accents\n",
        "# - max_df=0.5: Ignore terms that appear in more than 50% of documents\n",
        "# - ngram_range=(1,2): Include both unigrams and bigrams\n",
        "vectorizer = TfidfVectorizer(\n",
        "    strip_accents='unicode', \n",
        "    max_df=0.5, \n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "print(\"\\nFitting TF-IDF vectorizer...\")\n",
        "X_train_vectors = vectorizer.fit_transform(X_train)\n",
        "X_test_vectors = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Feature matrix shape: {X_train_vectors.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uwtK1k5ghe8G"
      },
      "source": [
        "## Model Training\n",
        "\n",
        "Training a Logistic Regression model with hyperparameters optimized using GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5FPvz2GvhlLr"
      },
      "outputs": [],
      "source": [
        "# Initialize Logistic Regression with optimized parameters\n",
        "# Parameters were optimized using GridSearchCV:\n",
        "# - solver='sag': Stochastic Average Gradient (good for large datasets)\n",
        "# - max_iter=10000: Maximum iterations for convergence\n",
        "# - C=2: Inverse regularization strength\n",
        "# - class_weight=None: No class balancing (balanced classes assumed)\n",
        "clf_log = LogisticRegression(\n",
        "    solver='sag', \n",
        "    max_iter=10000, \n",
        "    C=2, \n",
        "    class_weight=None,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training Logistic Regression model...\")\n",
        "clf_log.fit(X_train_vectors, y_train)\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# Evaluate model performance\n",
        "y_train_pred = clf_log.predict(X_train_vectors)\n",
        "y_test_pred = clf_log.predict(X_test_vectors)\n",
        "\n",
        "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nTraining F1 Score: {train_f1:.4f}\")\n",
        "print(f\"Testing F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Negative', 'Positive']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j6lBA71MikAT"
      },
      "source": [
        "## Save Model and Vectorizer\n",
        "\n",
        "The trained logistic regression model and TF-IDF vectorizer are saved using joblib (recommended for scikit-learn models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2nUJplMVixFo"
      },
      "outputs": [],
      "source": [
        "# Save vectorizer and model\n",
        "vectorizer_path = 'Vectorizer.pkl'\n",
        "model_path = 'SentimentNewton_Log.pkl'\n",
        "\n",
        "print(\"Saving vectorizer and model...\")\n",
        "joblib.dump(vectorizer, vectorizer_path)\n",
        "joblib.dump(clf_log, model_path)\n",
        "\n",
        "print(f\"✓ Vectorizer saved to: {vectorizer_path}\")\n",
        "print(f\"✓ Model saved to: {model_path}\")\n",
        "print(\"\\nModel training pipeline completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "submission_training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
