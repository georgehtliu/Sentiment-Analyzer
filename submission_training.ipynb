{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submission_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgehtliu/ignition-hack-2020/blob/master/submission_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB2nroT1bWso",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries and Data Input\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSU9cGUkbhrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import nltk \n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhWGRYIobrBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c3fafdb2-b828-44f8-e986-bc5fe1536252"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "path = \"training_data.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df[['Text','Sentiment']] #Set columns names as \"Text\" and \"Sentiment\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Please enter the path to your training_data.csv file in your Google Drive. (Right click the file on the left and click copy path and paste it in here.)/content/drive/My Drive/ML_Folder/training_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X1Ugm90cZRA",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5VR2_WEcfQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function which takes in a string and uses a regex query to return a string without punctuation \n",
        "def remove_punct(text):\n",
        "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60JeyGAcc1DZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "a4fd9809-605a-4a09-a7a5-fd184b2ca405"
      },
      "source": [
        "#Apply to dataframe column\n",
        "df['Text'] = df['Text'].map(lambda text: remove_punct(text))\n",
        "df.head(20) #Examine the data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I heart filling up dennisschaub desk    it mea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SocioMat  people create prettier younger and b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no way i dont want the tour to end</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HemalRadia Hi Amazing Brother Sending Limitles...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>flockmaster they are chocolate</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cHuMeee Just got home And from what Ive heard ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>chrisettefan yup yup especially when its it</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i have a new love matt lanter of  absolutely a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Grahams car looked really quotsnakeyquot on th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Why some people make me be evil towards them  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I think im fallin asleep ZZzz</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>nicolalalalala haha you girls are all filthy p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Oh myyy fjdhsjfjs David Cook is coming to Phil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>This weeekend is going by tooooo fast Oh well ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Doing laundry and checking emails after a long...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>skykemea a slot machine on my itouch Im so sad</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>markrock the earlier the better please Suggest...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>just finished packing things that Ill be bring...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Frannie Stalk Stalk How do you pronounce your ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>iconnectapp mine has crashed  times now and Iv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text  Sentiment\n",
              "0   I heart filling up dennisschaub desk    it mea...          1\n",
              "1   SocioMat  people create prettier younger and b...          1\n",
              "2                 no way i dont want the tour to end           0\n",
              "3   HemalRadia Hi Amazing Brother Sending Limitles...          1\n",
              "4                     flockmaster they are chocolate           1\n",
              "5   cHuMeee Just got home And from what Ive heard ...          1\n",
              "6        chrisettefan yup yup especially when its it           0\n",
              "7   i have a new love matt lanter of  absolutely a...          1\n",
              "8   Grahams car looked really quotsnakeyquot on th...          0\n",
              "9   Why some people make me be evil towards them  ...          0\n",
              "10                      I think im fallin asleep ZZzz          0\n",
              "11  nicolalalalala haha you girls are all filthy p...          0\n",
              "12  Oh myyy fjdhsjfjs David Cook is coming to Phil...          0\n",
              "13  This weeekend is going by tooooo fast Oh well ...          1\n",
              "14  Doing laundry and checking emails after a long...          1\n",
              "15    skykemea a slot machine on my itouch Im so sad           0\n",
              "16  markrock the earlier the better please Suggest...          1\n",
              "17  just finished packing things that Ill be bring...          0\n",
              "18  Frannie Stalk Stalk How do you pronounce your ...          1\n",
              "19  iconnectapp mine has crashed  times now and Iv...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1TMWrgJhW--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df['Text'])\n",
        "y = np.array(df['Sentiment'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', max_df=0.5, ngram_range=(1,2))\n",
        "X_train_vectors = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwtK1k5ghe8G",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FPvz2GvhlLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6bbaaaa5-da8b-47d4-e5a8-d4f03b3ae968"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_log = LogisticRegression(solver='sag', max_iter=10000, C=2, class_weight='dict')\n",
        "clf_log.fit(X_train_vectors, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=2, class_weight='dict', dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6lBA71MikAT",
        "colab_type": "text"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nUJplMVixFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle_out = open('Vectorizer','wb')\n",
        "Pickle = pickle.dump(vectorizer, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('SentimentNewton-Log','wb')\n",
        "Pickle = pickle.dump(clf_log, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}