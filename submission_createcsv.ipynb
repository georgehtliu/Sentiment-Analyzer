{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Sentiment Analyzer - Prediction Pipeline\n",
        "\n",
        "This notebook loads a trained sentiment analysis model and generates predictions for new text data.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/georgehtliu/sentiment-analyzer/blob/master/submission_createcsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFBc6GiFx_sB"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "- `joblib`: Loading saved scikit-learn models and vectorizers\n",
        "- `pandas`: Data manipulation and CSV handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eTXlXnetnws3"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_J4QiP7lyCys"
      },
      "source": [
        "## Load Model, Vectorizer, and Input Data\n",
        "\n",
        "This section loads the trained model, vectorizer, and the dataset to be classified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pX-mdMxht0eJ"
      },
      "outputs": [],
      "source": [
        "# File paths - adjust these if your files are in different locations\n",
        "model_path = \"SentimentNewton_Log.pkl\"\n",
        "vectorizer_path = \"Vectorizer.pkl\"\n",
        "judge_data_path = \"contestant_judgment.csv\"\n",
        "\n",
        "# For Google Colab, uncomment the following:\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = input('Please enter path to SentimentNewton_Log.pkl: ')\n",
        "vectorizer_path = input('Please enter path to Vectorizer.pkl: ')\n",
        "judge_data_path = input(\"Please enter the path to contestant_judgment.csv: \")\n",
        "\"\"\"\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "print(\"Loading trained model and vectorizer...\")\n",
        "try:\n",
        "    clf_log = joblib.load(model_path)\n",
        "    vectorizer = joblib.load(vectorizer_path)\n",
        "    print(f\"✓ Model loaded from: {model_path}\")\n",
        "    print(f\"✓ Vectorizer loaded from: {vectorizer_path}\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Could not find file. Make sure you have run submission_training.ipynb first.\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q7W6QAh_zB0m"
      },
      "source": [
        "## Data Preprocessing and Vectorization\n",
        "\n",
        "Apply the same preprocessing steps used during training, then vectorize the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WpXH32mrxfOy"
      },
      "outputs": [],
      "source": [
        "# Load the dataset to be classified\n",
        "print(f\"Loading data from: {judge_data_path}\")\n",
        "df_judge = pd.read_csv(judge_data_path)\n",
        "\n",
        "# Check if 'Text' column exists\n",
        "if 'Text' not in df_judge.columns:\n",
        "    print(\"Available columns:\", df_judge.columns.tolist())\n",
        "    raise ValueError(\"Dataset must contain a 'Text' column\")\n",
        "\n",
        "print(f\"Dataset shape: {df_judge.shape}\")\n",
        "print(\"\\nSample of input data:\")\n",
        "df_judge.head()\n",
        "\n",
        "# Apply the same preprocessing as training\n",
        "def remove_punct(text):\n",
        "    \"\"\"Remove punctuation and numbers from text.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = \"\".join([char for char in str(text) if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text\n",
        "\n",
        "print(\"\\nPreprocessing text data...\")\n",
        "df_judge['Text'] = df_judge['Text'].map(lambda text: remove_punct(text))\n",
        "\n",
        "# Vectorize the preprocessed text\n",
        "print(\"Vectorizing text data...\")\n",
        "X = df_judge['Text']\n",
        "X_vectors = vectorizer.transform(X)\n",
        "print(f\"Feature matrix shape: {X_vectors.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QZSBIb03zLKB"
      },
      "source": [
        "## Generate Predictions and Save Results\n",
        "\n",
        "Predict sentiment for all texts and save results to CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "peRoNeltxmsc",
        "outputId": "143da046-c21d-46bf-a4f5-1bd1e0e2adfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "print(\"Generating predictions...\")\n",
        "df_judge['Sentiment'] = clf_log.predict(X_vectors)\n",
        "\n",
        "# Display prediction distribution\n",
        "print(\"\\nPrediction distribution:\")\n",
        "print(df_judge['Sentiment'].value_counts())\n",
        "\n",
        "# Save results to CSV\n",
        "csv_path = 'predicted_labels.csv'  # Save to local directory by default\n",
        "\n",
        "# For Google Colab, uncomment to save to Drive:\n",
        "# csv_path = '/content/drive/My Drive/predicted_labels.csv'\n",
        "\n",
        "print(f\"\\nSaving predictions to: {csv_path}\")\n",
        "df_judge.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"\\n✓ Predictions saved successfully!\")\n",
        "print(f\"✓ Total predictions: {len(df_judge)}\")\n",
        "print(\"\\nDone!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "submission-createcsv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
